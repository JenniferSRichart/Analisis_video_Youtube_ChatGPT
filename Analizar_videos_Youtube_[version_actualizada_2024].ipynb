{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de vídeo de Youtube con ChatGPT"
      ],
      "metadata": {
        "id": "XtPHm_Q9gbg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8cOh0BsO_n_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f93c35-8972-4769-fefb-62b46964342a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hz30gjwi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hz30gjwi\n",
            "  Resolved https://github.com/openai/whisper.git to commit 25639fc17ddc013d56c594bfbf7644f2185fad84\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.9.27)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.8.30)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.21.0)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.2.3)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.10)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install yt-dlp\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import yt_dlp\n",
        "import openai\n",
        "import time\n",
        "import io\n",
        "\n",
        "# Configura tu clave de API de OpenAI (asegúrate de manejar esta información de forma segura)\n",
        "openai.api_key = \"Agregar API key\""
      ],
      "metadata": {
        "id": "215YaINf_ssl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EXTRACCIÓN DEL CONTENIDO DE YOUTUBE\n",
        "\n",
        "# Solicita al usuario que ingrese la URL del video de YouTube\n",
        "video_url = input(\"Ingresa la URL del video de YouTube: \") # changed this line to actually ask for input\n",
        "\n",
        "# Extrae el ID del video de la URL\n",
        "if \"v=\" in video_url:\n",
        "    video_id = video_url.split(\"v=\")[1]\n",
        "else:\n",
        "    # Handle cases where the URL doesn't contain \"v=\"\n",
        "    # For shorts, the ID is typically at the end of the URL\n",
        "    video_id = video_url.split(\"/\")[-1]\n",
        "\n",
        "# Descarga el audio del video de YouTube\n",
        "with yt_dlp.YoutubeDL({'format': 'm4a', 'outtmpl': f'{video_id}.m4a'}) as ydl:\n",
        "    ydl.download([video_url])\n",
        "\n",
        "# Cargar el modelo de Whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcribe el audio\n",
        "result = model.transcribe(f\"{video_id}.m4a\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL6TQRVaNvRT",
        "outputId": "b5f87829-cb03-41cf-8da4-26333815d4dc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingresa la URL del video de YouTube: https://youtube.com/shorts/px-SzeEA-ZM?si=hDpKFiMa1CGMW1ha\n",
            "[youtube] Extracting URL: https://youtube.com/shorts/px-SzeEA-ZM?si=hDpKFiMa1CGMW1ha\n",
            "[youtube] px-SzeEA-ZM: Downloading webpage\n",
            "[youtube] px-SzeEA-ZM: Downloading ios player API JSON\n",
            "[youtube] px-SzeEA-ZM: Downloading web creator player API JSON\n",
            "[youtube] px-SzeEA-ZM: Downloading m3u8 information\n",
            "[info] px-SzeEA-ZM: Downloading 1 format(s): 140\n",
            "[download] px-SzeEA-ZM?si=hDpKFiMa1CGMW1ha.m4a has already been downloaded\n",
            "[download] 100% of  886.83KiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda la transcripción en una variable\n",
        "transcript_text = result[\"text\"]\n",
        "print(transcript_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDVapCiCOzXN",
        "outputId": "4f93fa9b-30ea-4d22-f1d2-d43fb8521130"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ejercicio básico de Tai Chi N° 2 vas a separar tus pies más o menos una distancia entre las caderas y los hombros vas a subir tus brazos hasta la altura de los hombros una vez y los vas a descender hasta la altura de las caderas vas a dejar tus rodillas flexionadas vas a llevar una mano hacia adelante y la otra hacia brazo cuelta las palmas hacia arriba la mano sobre el hongo y empujando hacia adelante y vamos a repetirlo varias veces este ejercicio se llama rechazar al mono nota como una mano hacia adelante al no tiempo que la otra va hacia atrás mira esta mano que va a hacer la acción y hace donde va la acción\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANÁLISIS VIDEO YOUTUBE\n",
        "\n",
        "# Preparar el prompt para el análisis con GPT-4\n",
        "prompt = f\"Resume los puntos principales de este texto en formato viñeta:\\n{transcript_text}\"\n",
        "\n",
        "def get_gpt_response(messages):\n",
        "  response = openai.chat.completions.create(\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        # The model name may be incorrect or the user may not have access to it.\n",
        "        # Try using a different model, such as 'gpt-3.5-turbo'\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=4000,\n",
        "        timeout=400\n",
        "    )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "fh9mCMTFQ47u"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lanzar el primer prompt y almacenar la respuesta\n",
        "messages = [{\"role\": \"system\", \"content\": \" Eres un asistente increíblemente útil, capaz de generar respuestas perfectas a las peticiones que te hacen. Tu especialidad es el resumen de contenidos. Tu objetivo final es generar un resumen en viñetas perfecto\"}]\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "response = get_gpt_response(messages)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luH_lpjHQuV1",
        "outputId": "43883bf9-4aae-42f2-e41b-23bb8611d514"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Ejercicio básico de Tai Chi N° 2\n",
            "- Separar pies a distancia entre caderas y hombros\n",
            "- Subir brazos hasta altura de hombros y descender hasta caderas\n",
            "- Dejar rodillas flexionadas\n",
            "- Llevar una mano hacia adelante y otra hacia atrás\n",
            "- Palmas hacia arriba, empujando hacia adelante\n",
            "- Repetir varias veces, ejercicio llamado rechazar al mono\n",
            "- Observar mano que realiza la acción y a dónde va\n"
          ]
        }
      ]
    }
  ]
}